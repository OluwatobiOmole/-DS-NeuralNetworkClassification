{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import joblib\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.layers import Input,Dense, Dropout, Activation, Flatten, Embedding, Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, LSTM, SimpleRNN, Reshape\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Guardian Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random 20% portion of the dataset to work with. Next, split off a test set (10% of the extract) and a validation set (10% of the extract). The remaining 80% of the extract is be training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file from a URL\n",
    "url = 'https://storage.googleapis.com/kaggle-data-sets/2315156/3897165/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230508%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230508T172037Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=b9451b232c263533e2801719c94c9229339f16dbe04becc0c1502f235a3976fb6aa3b7f86f859252046e34b30e40eceea506761694ccab7a0127f4c0083e3fabe55d344fd85ea03d9783363d71af50057cca34db61369c2a0c2cc04afa1eede44c2a6faa220319360d3e37b85ec399d4853c4fc7178bf0b0abf68054e7fd1d58770d112b8f9a9cd417fbb01ece50c39f35116319ef1c76ea860b323905e1ad1d54312ef8fce9b5252dbaec6d3df65a3ca4235854598b00061e6d1ccaa7e327b758f8e7400fb64d8c5954e665ef459341cc0ab3484c14d82d5cde3e4ab8e61d4e7e229cae0dec2d7dee9e46750521dc77be012089df8bec45390b4eece3fd80cb'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "# Extract the files to a directory\n",
    "z.extractall('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>webTitle</th>\n",
       "      <th>webUrl</th>\n",
       "      <th>bodyContent</th>\n",
       "      <th>webPublicationDate</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us-news/2016/jan/31/iowa-caucus-underdog-candi...</td>\n",
       "      <td>US news</td>\n",
       "      <td>Iowa underdogs put on brave faces despite all ...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
       "      <td>As polling day looms and the cameras turn only...</td>\n",
       "      <td>2016-01-31T23:53:37Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-news/2016/jan/31/iowa-caucus-worlds-most-pa...</td>\n",
       "      <td>US news</td>\n",
       "      <td>Iowa caucus: hologram eagle and Jesus star on ...</td>\n",
       "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
       "      <td>In Des Moines on Sunday, the Guardian was give...</td>\n",
       "      <td>2016-01-31T23:46:28Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world/2016/jan/31/tanzania-britsh-helicopter-p...</td>\n",
       "      <td>World news</td>\n",
       "      <td>British pilot in Tanzania 'manoeuvred ​to save...</td>\n",
       "      <td>https://www.theguardian.com/world/2016/jan/31/...</td>\n",
       "      <td>A British pilot who was shot dead by an elepha...</td>\n",
       "      <td>2016-01-31T23:43:48Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>football/2016/jan/31/late-winner-gets-usa-off-...</td>\n",
       "      <td>Football</td>\n",
       "      <td>USA 3-2 Iceland | International friendly match...</td>\n",
       "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
       "      <td>USA took a step toward shaking off the ghosts ...</td>\n",
       "      <td>2016-01-31T23:30:49Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>football/2016/jan/31/blackburn-paul-lambert-ox...</td>\n",
       "      <td>Football</td>\n",
       "      <td>Reinvigorated Paul Lambert reflects after impr...</td>\n",
       "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
       "      <td>The clean-shaven, spectacle free and suspiciou...</td>\n",
       "      <td>2016-01-31T22:30:10Z</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          article_id sectionName  \\\n",
       "0  us-news/2016/jan/31/iowa-caucus-underdog-candi...     US news   \n",
       "1  us-news/2016/jan/31/iowa-caucus-worlds-most-pa...     US news   \n",
       "2  world/2016/jan/31/tanzania-britsh-helicopter-p...  World news   \n",
       "3  football/2016/jan/31/late-winner-gets-usa-off-...    Football   \n",
       "4  football/2016/jan/31/blackburn-paul-lambert-ox...    Football   \n",
       "\n",
       "                                            webTitle  \\\n",
       "0  Iowa underdogs put on brave faces despite all ...   \n",
       "1  Iowa caucus: hologram eagle and Jesus star on ...   \n",
       "2  British pilot in Tanzania 'manoeuvred ​to save...   \n",
       "3  USA 3-2 Iceland | International friendly match...   \n",
       "4  Reinvigorated Paul Lambert reflects after impr...   \n",
       "\n",
       "                                              webUrl  \\\n",
       "0  https://www.theguardian.com/us-news/2016/jan/3...   \n",
       "1  https://www.theguardian.com/us-news/2016/jan/3...   \n",
       "2  https://www.theguardian.com/world/2016/jan/31/...   \n",
       "3  https://www.theguardian.com/football/2016/jan/...   \n",
       "4  https://www.theguardian.com/football/2016/jan/...   \n",
       "\n",
       "                                         bodyContent    webPublicationDate  id  \n",
       "0  As polling day looms and the cameras turn only...  2016-01-31T23:53:37Z   1  \n",
       "1  In Des Moines on Sunday, the Guardian was give...  2016-01-31T23:46:28Z   2  \n",
       "2  A British pilot who was shot dead by an elepha...  2016-01-31T23:43:48Z   3  \n",
       "3  USA took a step toward shaking off the ghosts ...  2016-01-31T23:30:49Z   4  \n",
       "4  The clean-shaven, spectacle free and suspiciou...  2016-01-31T22:30:10Z   5  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a variable called \"data\"\n",
    "data = pd.read_csv('datasets/guardian_articles.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns\n",
    "data = data.drop(['article_id', 'webUrl','webPublicationDate', 'id' ], axis=1)\n",
    "extract = data.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    # Convert the text to a string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove unwanted characters using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "# Preprocess the text extract in the extractframe\n",
    "extract['sectionName'] = extract['sectionName'].apply(preprocess_text)\n",
    "extract['webTitle'] = extract['webTitle'].apply(preprocess_text)\n",
    "extract['bodyContent'] = extract['bodyContent'].apply(preprocess_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Truncated dataset into Training, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing text and Pad sequences to ensure equal length\n",
    "max_features = 5000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(extract['bodyContent'].values)\n",
    "X = tokenizer.texts_to_sequences(extract['bodyContent'].values)\n",
    "X = pad_sequences(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the labels to numerical values\n",
    "label_dict = {label: index for index, label in enumerate(extract['sectionName'].unique())}\n",
    "y = [label_dict[label] for label in extract['sectionName']]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check shape of training, test and validation sets after split top ensure correct split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)\n",
    "print('Val shape:', X_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Variants (Basic RNN, LSTM and Multi-Layer LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters that are used to define the architecture and settings of the RNN model\n",
    "max_features = 5000  #maximum number of words to keep based on word frequency\n",
    "maxlen = 400 #maximum number of words in a single sentence.\n",
    "embedding_dims = 16 #dimensionality of the output space\n",
    "epochs = 5 #iterations\n",
    "\n",
    "# Preprocess by padding the sequences to the same length \n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=maxlen)\n",
    "\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)\n",
    "print('Validation shape:', X_val.shape)\n",
    "\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code  converts the integer-encoded sequences to strings using the sequences_to_texts() method. Then, it splits each string into a list of words using the split() method so it can be accepted into the fit_on_texts method. This entire process converts the raw text input into a numerical format that can be processed by a RNN model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RNN with single layer (No Embeddings Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model architecture\n",
    "modelRNN = tf.keras.Sequential()\n",
    "modelRNN.add(tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)))\n",
    "modelRNN.add(tf.keras.layers.Dropout(0.2))\n",
    "modelRNN.add(tf.keras.layers.SimpleRNN(embedding_dims))\n",
    "modelRNN.add(tf.keras.layers.Dropout(0.2))\n",
    "modelRNN.add(tf.keras.layers.Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "modelRNN.summary()\n",
    "\n",
    "# Compile the modelRNN\n",
    "modelRNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelRNN and save the history of accuracy and loss during training\n",
    "historymodelRNN = modelRNN.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRNN.save(\"/Users/tobi/SavedModels/modelRNN.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelRNN.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelRNN.history['accuracy'])\n",
    "plt.plot(historymodelRNN.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelRNN.history['loss'])\n",
    "plt.plot(historymodelRNN.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LSTM with single layer (No Embeddings Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model architecture\n",
    "modelLSTM = tf.keras.Sequential()\n",
    "modelLSTM.add(tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)))\n",
    "modelLSTM.add(Dropout(0.2))\n",
    "modelLSTM.add(tf.keras.layers.LSTM(embedding_dims))\n",
    "modelLSTM.add(Dropout(0.2))\n",
    "modelLSTM.add(tf.keras.layers.Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "modelLSTM.summary()\n",
    "\n",
    "# Compile the modelLSTM\n",
    "modelLSTM.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelLSTM and save the history of accuracy and loss during training\n",
    "historymodelLSTM = modelLSTM.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM.save(\"/Users/tobi/SavedModels/modelLSTM.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic LSTM with single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelLSTM.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelLSTM.history['accuracy'])\n",
    "plt.plot(historymodelLSTM.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelLSTM.history['loss'])\n",
    "plt.plot(historymodelLSTM.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Basic RNN model and LSTM with single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historymodelRNN.history['accuracy'], linestyle='solid', color='blue')\n",
    "plt.plot(historymodelRNN.history['val_accuracy'], linestyle='dotted', color='blue')\n",
    "plt.plot(historymodelLSTM.history['accuracy'], linestyle='solid', color='orange')\n",
    "plt.plot(historymodelLSTM.history['val_accuracy'], linestyle='dotted', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['RNN Train', 'RNN Val', 'LSTM Train', 'LSTM Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with multiple layers (No Embeddings Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model architecture\n",
    "modelLSTM2 = tf.keras.Sequential()\n",
    "modelLSTM2.add(tf.keras.layers.Reshape((X_train.shape[1], 1), input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Add 2 LSTM layers\n",
    "modelLSTM2.add(tf.keras.layers.LSTM(embedding_dims, return_sequences=True))\n",
    "modelLSTM2.add(Dropout(0.2))\n",
    "modelLSTM2.add(tf.keras.layers.LSTM(embedding_dims))\n",
    "modelLSTM2.add(Dropout(0.2))\n",
    "\n",
    "modelLSTM2.add(tf.keras.layers.Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "modelLSTM2.summary()\n",
    "\n",
    "# Compile the modelLSTM2\n",
    "modelLSTM2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelLSTM2 and save the history of accuracy and loss during training\n",
    "historymodelLSTM2 = modelLSTM2.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTM2.save(\"/Users/tobi/SavedModels/modelLSTM2.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with Multiple Layers Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelLSTM2.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelLSTM2.history['accuracy'])\n",
    "plt.plot(historymodelLSTM2.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelLSTM2.history['loss'])\n",
    "plt.plot(historymodelLSTM2.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Single Layer LSTM with Mutliple layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historymodelLSTM2.history['accuracy'], linestyle='solid', color='blue')\n",
    "plt.plot(historymodelLSTM2.history['val_accuracy'], linestyle='dotted', color='blue')\n",
    "plt.plot(historymodelLSTM.history['accuracy'], linestyle='solid', color='orange')\n",
    "plt.plot(historymodelLSTM.history['val_accuracy'], linestyle='dotted', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM Multiple Train', 'LSTM Multiple Val', 'LSTM Single Train', 'LSTM Multiple Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - On the fly Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model architecture with the On the fly Embeddings by adding an embeddings layer\n",
    "modelOnTheFly = tf.keras.Sequential()\n",
    "modelOnTheFly.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "\n",
    "# Add 2 LSTM layers\n",
    "modelOnTheFly.add(tf.keras.layers.LSTM(embedding_dims, return_sequences=True))\n",
    "modelOnTheFly.add(Dropout(0.2))\n",
    "modelOnTheFly.add(tf.keras.layers.LSTM(embedding_dims))\n",
    "modelOnTheFly.add(Dropout(0.2))\n",
    "\n",
    "modelOnTheFly.add(tf.keras.layers.Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "modelOnTheFly.summary()\n",
    "\n",
    "# Compile the modelOnTheFly\n",
    "modelOnTheFly.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelOnTheFly and save the history of accuracy and loss during training\n",
    "historymodelOnTheFly = modelOnTheFly.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelOnTheFly.save(\"/Users/tobi/SavedModels/modelOnTheFly.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelOnTheFly.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelOnTheFly.history['accuracy'])\n",
    "plt.plot(historymodelOnTheFly.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelOnTheFly.history['loss'])\n",
    "plt.plot(historymodelOnTheFly.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II - Pre-trained Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"loading embedding\")\n",
    "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\", output_shape=[20],\n",
    "#                            input_shape=[], dtype=tf.string)\n",
    "\n",
    "# modelTrainedEmbeddings = tf.keras.Sequential()\n",
    "# modelTrainedEmbeddings.add(hub_layer)\n",
    "# modelTrainedEmbeddings.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "# modelTrainedEmbeddings.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# modelTrainedEmbeddings.summary()\n",
    "\n",
    "\n",
    "# #modelTrainedEmbeddings.summary()\n",
    "\n",
    "# # Compile and train the modelTrainedEmbeddings\n",
    "# modelTrainedEmbeddings.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = modelTrainedEmbeddings.fit(x_train.astype(str), target_train, batch_size=32, epochs=5, validation_data=(x_val.astype(str), target_val))\n",
    "\n",
    "# #Plot the accuracy during training\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# epochs_range = range(1, epochs+1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of Words instead of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bag-of-words model architecture\n",
    "modelBagOfWords = tf.keras.Sequential()\n",
    "modelBagOfWords.add(tf.keras.layers.Input(shape=(maxlen,)))\n",
    "modelBagOfWords.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "modelBagOfWords.add(tf.keras.layers.Dropout(0.5))\n",
    "modelBagOfWords.add(tf.keras.layers.Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "modelBagOfWords.summary()\n",
    "\n",
    "# Compile the modelBagOfWords\n",
    "modelBagOfWords.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelBagOfWords and save the history of accuracy and loss during training\n",
    "historymodelBagOfWords = modelBagOfWords.fit(X_train, y_train,\n",
    "                              epochs=epochs,\n",
    "                              batch_size=32,\n",
    "                              validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBagOfWords.save(\"/Users/tobi/SavedModels/modelBagOfWords.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelBagOfWords.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelBagOfWords.history['accuracy'])\n",
    "plt.plot(historymodelBagOfWords.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelBagOfWords.history['loss'])\n",
    "plt.plot(historymodelBagOfWords.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of On the Fly Embeddings Model with Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historymodelOnTheFly.history['accuracy'], linestyle='solid', color='blue')\n",
    "plt.plot(historymodelOnTheFly.history['val_accuracy'], linestyle='dotted', color='blue')\n",
    "plt.plot(historymodelBagOfWords.history['accuracy'], linestyle='solid', color='orange')\n",
    "plt.plot(historymodelBagOfWords.history['val_accuracy'], linestyle='dotted', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['LSTM Multiple Train', 'LSTM Multiple Val', 'BagOfWords Train', 'BagOfWords Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs as an Alternative to an LSTM Solution\n",
    "An implementation of using a CNN with multiple and heterogeneous kernel sizes as an alternative to an LSTM solution for text classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define CNN model architecture\n",
    "modelAltCNN = Sequential()\n",
    "modelAltCNN.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "modelAltCNN.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "modelAltCNN.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "modelAltCNN.add(Dropout(0.2))\n",
    "modelAltCNN.add(GlobalMaxPooling1D())\n",
    "modelAltCNN.add(Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "modelAltCNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with validation data\n",
    "historymodelAltCNN = modelAltCNN.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAltCNN.save(\"/Users/tobi/SavedModels/modelAltCNN.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelAltCNN.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelAltCNN.history['accuracy'])\n",
    "plt.plot(historymodelAltCNN.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelAltCNN.history['loss'])\n",
    "plt.plot(historymodelAltCNN.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs as an Additional Layer Before an LSTM Solution\n",
    "An implementation of using a CNN with multiple and heterogeneous kernel sizes as an additional layer before an LSTM solution for text classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combined CNN and LSTM model architecture\n",
    "modelLSTMCNN = Sequential()\n",
    "modelLSTMCNN.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "modelLSTMCNN.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "modelLSTMCNN.add(Dropout(0.2))\n",
    "modelLSTMCNN.add(GlobalMaxPooling1D())\n",
    "modelLSTMCNN.add(Reshape((1, -1)))  \n",
    "modelLSTMCNN.add(LSTM(embedding_dims))\n",
    "modelLSTMCNN.add(Dense(len(label_dict), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "modelLSTMCNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with validation data\n",
    "historymodelLSTMCNN = modelLSTMCNN.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLSTMCNN.save(\"/Users/tobi/SavedModels/modelLSTMCNN.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = modelLSTMCNN.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\" , loss)\n",
    "print(\"Test Accuracy:\" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(historymodelAltCNN.history['accuracy'])\n",
    "plt.plot(historymodelAltCNN.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(historymodelAltCNN.history['loss'])\n",
    "plt.plot(historymodelAltCNN.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of CNN as alternative to LSTM and CNN with LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historymodelAltCNN.history['accuracy'], linestyle='solid', color='blue')\n",
    "plt.plot(historymodelAltCNN.history['val_accuracy'], linestyle='dotted', color='blue')\n",
    "plt.plot(historymodelLSTMCNN.history['accuracy'], linestyle='solid', color='orange')\n",
    "plt.plot(historymodelLSTMCNN.history['val_accuracy'], linestyle='dotted', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['CNN as Alternative to LSTM Train', 'CNN as Alternative to LSTMVal', 'CNN before LSTM Train', 'CNN before LSTM Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to Non-Neural Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Naive Bayes model as the non neural method, retrain the data with this model and checking its "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "n_iterations = 5\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Create a Naive Bayes model\n",
    "    modelNB = MultinomialNB()\n",
    "\n",
    "    # Train the model on the training set\n",
    "    modelNB.fit(X_train,y_train)\n",
    "\n",
    "    # Evaluate the model on the training set and validation set\n",
    "    train_acc = modelNB.score(X_train, y_train)\n",
    "    val_acc = modelNB.score(X_val, y_val)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "# Calculate the average accuracies\n",
    "avg_train_acc = sum(train_accs) / n_iterations\n",
    "avg_val_acc = sum(val_accs) / n_iterations\n",
    "\n",
    "print(\"Average training accuracy:\", avg_train_acc)\n",
    "print(\"Average validation accuracy:\", avg_val_acc)\n",
    "\n",
    "# Plot the accuracies\n",
    "plt.plot([avg_train_acc, avg_val_acc], marker='o')\n",
    "plt.xticks([0, 1], ['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.ylim([0, 0.2])\n",
    "plt.title('Naive Bayes Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(modelNB, 'naive_bayes_model.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparion of non-neural method to best performing neural method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training and validation accuracies for modelAltCNN\n",
    "plt.plot(historymodelAltCNN.history['accuracy'])\n",
    "plt.plot(historymodelAltCNN.history['val_accuracy'])\n",
    "\n",
    "# Plot training and validation accuracies for RandomForestClassifier\n",
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)\n",
    "\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch/Iteration')\n",
    "plt.legend(['CNN as Alternative to LSTM Train Train', 'CNN as Alternative to LSTM Train Validation', 'RF Train', 'RF Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the web title column as an input in conjuction with the body content column into an LSTM model. We must use values of the webtitle to create new training, test and validation sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First tokenize and pad the webtitles values into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing text and Pad sequences to ensure equal length for web titles\n",
    "tokenizer_web_title = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer_web_title.fit_on_texts(extract['webTitle'].values)\n",
    "X_web_title = tokenizer_web_title.texts_to_sequences(extract['webTitle'].values)\n",
    "X_web_title = pad_sequences(X_web_title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting a new testing, training and validation sets with different contents. One containing body content values and one containing web title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_web_title_train, X_web_title_test, X_body_content_train, X_body_content_test, y_train, y_test = train_test_split(\n",
    "    X_web_title, X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_web_title_val, X_web_title_test, X_body_content_val, X_body_content_test, y_val, y_test = train_test_split(\n",
    "    X_web_title_test, X_body_content_test, y_test, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess by padding the sequences to the same length \n",
    "X_web_title_train = sequence.pad_sequences(X_web_title_train, maxlen=maxlen)\n",
    "X_body_content_train = sequence.pad_sequences(X_body_content_train, maxlen=maxlen)\n",
    "X_web_title_val = sequence.pad_sequences(X_web_title_val, maxlen=maxlen)\n",
    "X_body_content_val = sequence.pad_sequences(X_body_content_val, maxlen=maxlen)\n",
    "X_web_title_test = sequence.pad_sequences(X_web_title_test, maxlen=maxlen)\n",
    "X_body_content_test = sequence.pad_sequences(X_body_content_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layers\n",
    "input_web_title = Input(shape=(maxlen,), name='input_web_title')\n",
    "input_body_content = Input(shape=(maxlen,), name='input_body_content')\n",
    "\n",
    "# Embedding layer for web title input\n",
    "embedding_web_title = Embedding(max_features, embedding_dims, input_length=maxlen)(input_web_title)\n",
    "# Embedding layer for body content input\n",
    "embedding_body_content = Embedding(max_features, embedding_dims, input_length=maxlen)(input_body_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer for web title input\n",
    "lstm_web_title = LSTM(embedding_dims)(embedding_web_title)\n",
    "dropout_lstm_web_title = Dropout(0.2)(lstm_web_title)\n",
    "\n",
    "# LSTM layer for body content input\n",
    "lstm_body_content = LSTM(embedding_dims)(embedding_body_content)\n",
    "lstm_body_content_dropout = Dropout(0.2)(lstm_body_content)\n",
    "\n",
    "# Concatenate the outputs of the LSTM layers\n",
    "merged = Concatenate()([lstm_web_title, lstm_body_content])\n",
    "\n",
    "# Dense layer for prediction\n",
    "output = Dense(len(label_dict), activation='softmax')(merged)\n",
    "\n",
    "# Create the modelTwoInputs with multiple inputs\n",
    "modelTwoInputs = Model(inputs=[input_web_title, input_body_content], outputs=output)\n",
    "\n",
    "# Compile the modelTwoInputs\n",
    "modelTwoInputs.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelTwoInputs with validation data\n",
    "historymodelTwoInputs = modelTwoInputs.fit(\n",
    "    [X_web_title_train, X_body_content_train],  # Input data for both web title and body content\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_web_title_val, X_body_content_val], y_val) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTwoInputs.save(\"/Users/tobi/SavedModels/modelTwoInputs.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with test data\n",
    "test_loss, test_acc = modelTwoInputs.evaluate([X_web_title_test, X_body_content_test], y_test, verbose=2)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy curves\n",
    "plt.plot(historymodelTwoInputs.history['accuracy'])\n",
    "plt.plot(historymodelTwoInputs.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Two Input Model with best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historymodelAltCNN.history['accuracy'], linestyle='solid', color='blue')\n",
    "plt.plot(historymodelAltCNN.history['val_accuracy'], linestyle='dotted', color='blue')\n",
    "plt.plot(historymodelTwoInputs.history['accuracy'], linestyle='solid', color='orange')\n",
    "plt.plot(historymodelTwoInputs.history['val_accuracy'], linestyle='dotted', color='orange')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['CNN as Alternative to LSTM Train', 'CNN as Alternative to LSTMVal', 'Two Inputs Model Train', 'Two Inputs Model Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
